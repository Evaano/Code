{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only take the class Simple_KNN ignor iris data and shit. Also change it up a bit, GPT or whatever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "irisX, irisy = load_iris(return_X_y=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(irisX, irisy, test_size=0.33, stratify=irisy)\n",
    "\n",
    "class simple_KNN:\n",
    "    def __init__(self, K=1, verbose=True):\n",
    "        self.distance = self.euclidean_distance\n",
    "        self.K = K\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.numTrainingItems = X.shape[0]\n",
    "        self.numFeatures = X.shape[1]\n",
    "        self.modelX = X\n",
    "        self.modelY = y\n",
    "        self.labelsPresent = np.unique(self.modelY)\n",
    "        if self.verbose:\n",
    "            print(f\"There are {self.numTrainingItems} training examples, each described by\")\n",
    "            print(f\"self.modelX is a 2D array of shape {self.modelX.shape}\")\n",
    "            print(f\"self.modelY is a list with {len(self.modelY)} entries, each being one of the labels associated with the training examples\")\n",
    "\n",
    "    def predict(self, newItems):\n",
    "        numToPredict = newItems.shape[0]\n",
    "        predictions = np.empty(numToPredict)\n",
    "        for item in range(numToPredict):\n",
    "            thisPrediction = self.predict_new_item(newItems[item])\n",
    "            predictions[item] = thisPrediction\n",
    "        return predictions\n",
    "    \n",
    "    def predict_new_item(self, newItem):\n",
    "        distFromNewItem = np.zeros((self.numTrainingItems))\n",
    "        \n",
    "        for stored_example in range(self.numTrainingItems):\n",
    "            distFromNewItem[stored_example] = self.distance(newItem, self.modelX[stored_example])\n",
    "\n",
    "        # Step 2: Get indexes of the k nearest neighbours for our new item\n",
    "        closestK = self.get_ids_of_k_closest(self.K, distFromNewItem)\n",
    "\n",
    "        labelcounts = np.zeros(len(self.labelsPresent))\n",
    "        for k in range(self.K):\n",
    "            thisindex = closestK[k]\n",
    "            thislabel = self.modelY[thisindex]\n",
    "            labelcounts[thislabel] += 1\n",
    "        thisPrediction = np.argmax(labelcounts)\n",
    "        return thisPrediction\n",
    "        \n",
    "    def euclidean_distance(self, item1, item2):\n",
    "        assert item1.shape[0] == item2.shape[0]\n",
    "        distance = 0.0\n",
    "        for feature in range(item1.shape[0]):\n",
    "            difference = item1[feature] - item2[feature]\n",
    "            distance = distance + difference * difference\n",
    "        return math.sqrt(distance)\n",
    "    \n",
    "    def get_ids_of_k_closest(self, K, distFromNewItem):\n",
    "        sorted_indices = np.argsort(distFromNewItem)\n",
    "        closestK = sorted_indices[:K]\n",
    "        return closestK\n",
    "    \n",
    "# Create and fit the model\n",
    "myKNNmodel = simple_KNN()\n",
    "myKNNmodel.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
